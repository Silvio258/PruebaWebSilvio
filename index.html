<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    <header>
        <h1> ¿Podria la Inteligencia Artificial ser una amenaza para la humanidad? </h1>
        <img src="https://imageio.forbes.com/specials-images/imageserve/647994d97ff0e466a60e1090/The-15-Biggest-Risks-Of-Artificial-Intelligence/960x0.jpg?height=473&width=711&fit=bounds" alt="Imagen de un robot" height="200px" width="300px">

        <h3> -Compartido por Silvio Vigil-</h3>
    </header>
    <body>
        <h2> Preocupaciones de seguridad </h2>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/osmuCTVt4H4?si=f2cSimGUkvc8rr3i" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        <p>El uso de la inteligencia artificial (IA) está aumentando rápidamente en muchos sectores, incluyendo el gobierno, la banca, la industria, la salud y la educación. A medida que se desarrollen nuevos algoritmos y se mejore la capacidad de procesamiento, la IA se está convirtiendo en una herramienta cada vez más valiosa para resolver problemas complejos y mejorar la eficiencia. Sin embargo, también plantea desafíos importantes en cuanto a seguridad y riesgos.</p>        
        <ul>
            <li>La IA es vulnerable a los ataques de hackers y otros delincuentes cibernéticos. Al igual que cualquier otro sistema informático, los sistemas de IA pueden ser objeto de ataques que pueden interrumpir su funcionamiento u obtener información confidencial. Además, los ataques a la IA pueden tener un impacto mucho más significativo que los ataques a los sistemas tradicionales, ya que la IA está involucrada en muchas decisiones críticas y puede tener consecuencias graves si falla.</li>
            <li>La IA puede ser utilizada para fines malintencionados. Por ejemplo, los sistemas de reconocimiento facial pueden ser utilizados para realizar vigilancia masiva, mientras que los sistemas de IA pueden ser utilizados para distribuir spam y malware. Además, la IA también puede ser utilizada para manipular información y crear noticias falsas, lo que puede tener graves consecuencias para la democracia y la sociedad en general.</li>
            <li>La IA puede ser utilizada para discriminar y perpetuar la desigualdad. Muchos sistemas de IA se basan en datos que reflejan las desigualdades existentes en la sociedad, lo que puede perpetuar la discriminación y la desigualdad. Además, los sistemas de IA pueden ser utilizados para tomar decisiones basadas en estereotipos y prejuicios, lo que puede tener graves consecuencias para ciertos grupos de personas.</li>
         </ul>
        <h3>¿Cuales son los principales riesgos?</h3>
        <ol>
            <li>Responsabilidad difusa </li>
            <p> Por mucho que algunos vendan lo contrario, la realidad es que la IA no es infalible. De hecho, aún se recuerda cuando ChatGPT inventó los datos científicos en un texto que ayudó a elaborar. Ante este escenario, si una empresa proporciona información falsa debido a la IA en una labor que está realizando para un cliente es imposible saber quién es el responsable. En la actualidad no existe ninguna certeza que indique que las consecuencias de los fallos de esta tecnología sean culpa de la empresa o del propio proveedor de IA. Esta falta de regulación crea incertidumbre en las compañías. De ahí que la Unión Europea haya tratado de paliar el problema siendo uno de los primeros territorios donde se han detallado la responsabilidad en el ámbito de la IA.</p>
            <li>Información falsa</li>
            <p>La IA es capaz de generar instantáneas falsas de líderes políticos o empresariales y también de imitar la voz de cualquiera. Esta característica en manos de personas inadecuadas puede tener graves consecuencias hasta para el sistema político de un país. Y, también, puede generar perjuicios irreparables para las empresas al ver empeñada su imagen de marca por una campaña en contra creada por cualquiera con acceso a las herramientas de IA adecuadas.</p>
            <li>Amenaza para la ciberseguridad </li>
            <p>Las aplicaciones de IA manejan gran cantidad de datos sensibles de los que buena parte no se sabe muy bien donde almacenan. Esto eleva su atractivo para los amigos de lo ajeno, que con un ataque pueden lograr un robo de información a gran escala. Los Estados, pero también las empresas, están empezando a tener en cuenta este peligro que puede generarse con un mal uso de esta tecnología.</p>
            <li>Desmotivación de las plantillas</li>
            <p>Se lleva hablando tiempo de que la IA supondrá la eliminación de millones de puestos de trabajo para sustituirlos por máquinas. Es obvio que este escenario genera una importante desmotivación entre los empleados de las empresas. De ahí que en muchos negocios se estén empezando a estudiar los efectos psicológicos que sobre las plantillas puede generar la incorporación de este tipo de herramientas.</p>
        </ol>
    </body>
    <footer>
        <h3>-Links bibliograficos de donde se recupero la informacion-</h3>
        <table> 
            <td>
                <tr>   
                    <img src="https://www.osservatoreromano.va/content/dam/or/images/es/2024/01/004/varobj22671466obj2035841.jpg/_jcr_content/renditions/cq5dam.thumbnail.cropped.500.281.jpeg" alt="Robot deshaciendose en partes" height="150" width="250">
                     <p>https://fepsu.es/el-uso-de-la-inteligencia-artificial-y-los-riesgos-para-la-seguridad-publica/</p>
                    </tr>
                <tr> 
                    <img src="https://fepsu.es/wp-content/uploads/elementor/thumbs/pexels-pixabay-373543-scaled-q1h3or9nwcr5bj30oh9sbpjaysedcjv4derdneqzi0.jpg" alt="Cables azules" height="150" width="250">
                    <p>https://fepsu.es/el-uso-de-la-inteligencia-artificial-y-los-riesgos-para-la-seguridad-publica/</p>
                </tr>
            </td>
        </table>
    </footer>
</body>
</html>